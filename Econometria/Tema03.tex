
\chapter[Heteroscedasticidad y autocorrelaci\'on.]{Heteroscedasticidad y autocorrelaci\'on. \\
\normalsize Causas y consecuencias de la heteroscedasticidad y de la autocorrelaci\'on. Inferencia robusta a la heterocedasticidad y a la autocorrelaci\'on. Estimaci\'on por m\'inimos cuadrados generalizados factibles. Principales contrastes de heterocedasticidad y de autocorrelaci\'on.}


\sectioncol{Introducci\'on.}

Al analizar las propiedades de los estimadores $MCO$, entre las hip\'otesis de partida asumimos que el t\'ermino de error tiene una matriz de covarianzas escalar: todos sus elementos son cero, excepto los de la diagonal principal, y estos son todos iguales a $\sigma_{u}^{2}$. Sin embargo, existen situaciones en las que la matriz de covarianzas tiene una estructura m\'as compleja; en estas situaciones las propiedades analizadas bajo este supuesto podr\'ian dejar de ser v\'alidas.

Una de estas situaciones se produce cuando la matriz es diagonal, pero sus elementos diagonales son distintos unos de otros, es decir, $Var(u_{i})=\sigma_{i}^{2}$, con $\sigma_{i}^{2}\neq\sigma_{j}^{2}$ si $i\neq j$. A esta situaci\'on se la denomina \textbf{heteroscedasticidad}. Al caso en que la varianza de $u_{i}$ es constante se le llama \textbf{homoscedasticidad}.

Una segunda situaci\'on ocurre cuando los t\'erminos de error de distintas observaciones no son independientes entre s\'i, es decir, la matriz de covarianzas no es diagonal. A esta situaci\'on se la denomina \textbf{autocorrelaci\'on},
para reflejar el hecho de que el t\'ermino de error est\'a correlado consigo mismo.

A la hora de estimar un modelo econom\'etrico no se puede suponer la ausencia de heteroscedasticidad y autocorrelaci\'on sino que es necesario analizar en qu\'e medida afectan a la estimaci\'on. Si bien la hip\'otesis de matriz de covarianzas escalar no afecta a la insesgadez del estimador, si afecta a su eficiencia y a los distintos contrastes que se realizan sobre sus t\'erminos.

Veremos c\'omo afecta la presencia de estos fen\'omenos al estimador de m\'inimos cuadrados ordinarios, y que t\'ecnicas se pueden aplicar para minimizar sus efectos.


\sectioncol{Causas y consecuencias de la heteroscedasticidad y de la autocorrelaci\'on.}

\subsectioncol{Posibles causas de heteroscedasticidad.}

La homoscedasticidad supone que la varianza del t\'ermino de perturbaci\'on del modelo es constante. Si embargo, esto no es lo habitual, ni mucho menos. Hay varias razones por las que puede aparecer la heteroscedasticidad.

\begin{itemize}
\item Muchas variables explicativas acent\'uan la probabilidad de que esxista una mayor variabilidad en el comportamieto de los agentes econ\'omicos. Por ejemplo, a medida que aumentan los ingresos de las familias tienen m\'as disponibilidad de fondos una vez han cubierto las necesidades b\'asicas, y por tanto tenen mayor margen de decisi\'on sobre la cantidad que quieren destinar al consumo y al ahorro. En general esto ocurre porque los agentes tienen m\'as grados de libertad en su comportamiento. Esto provoca que la variabilidad de la perturbaci\'on aumente a medida que lo hacen las variables explicativas.
\item La mejora de las t\'ecnicas de recolecci\'on de datos hace que los errores disminuyan, y por tanto disminuye la variabilidad de la perturbaci\'on que corresponda a los errores de observaci\'on.
\item Si los datos de los que se dispone corresponden a la agregaci\'on de datos correspondientes a distintos grupos, normalmente su variabilidad depende del tama\~no del grupo que se agrega.
\item Si el modelo est\'a mal especificado, bien porque no incluya variables relevantes, bien por una transformaci\'on incorrecta de los datos (niveles vs logaritmos), tambi\'en se produce heteroscedasticidad. Esta es especialmente grave, ya que puede que viole tambi\'en la hip\'otesis de exogeneidad.
\end{itemize}

Normalmente la heteroscedasticidad es m\'as frecuente con los datos de corte transversal, ya que se refieren a distintos individuos, aunque tambi\'en puede aparecer en datos de series temporales.

\subsectioncol{Consecuencias de la heteroscedasticidad.}

Si los datos presentan heterocedasticidad, el estimador de m\'inimos cuadrados ordinarios sigue siendo lineal, insesgado y consistente, ya que para obtener estas propiedades no se asume en ning\'un momento homoscedasticidad.

Tampoco se ve afectada la validez de $R^2$ y $\bar{R}^2$ como medidas de la bondad del ajuste, ya que ambos son estimadores consistentes del $R^2$ poblacional tambi\'en en presencia de heterocedasticidad.

Sin embargo, para calcular la matriz de varianzas y cobarianzas del estimador s\'i que asumimos homoscedasticidad, por lo que los estimadors de las varianzas de los coeficientes ya no ser\'an insesgados, y el estad\'istico $t$ no se distribuir\'a siguiendo una $t$ de student, con lo que no podremos calcular intervalos de confianza de los estimadores. Del mismo modo, los estad\'isticos $F$ no seguir\'an una distribuci\'on $F$, y el contraste de los multiplicadores de Lagrange dejar\'a de ser v\'alido.

Tambi\'en hemos visto que el teorema de Gauss-Markov, q	ue nos dice que el estimador de m\'inimos cuadrados ordinarios es el estimador lineal insesgado de m\'inima varianza deja de ser v\'alido, ya que asume de forma crucial la hip\'otesis de homoscedasticidad. Por tanto, el estimador ya no es ELIO, ni tampoco asint\'oticamente eficiente.

\subsectioncol{Posibles causas de autocorrelaci\'on.}

La autocorrelaci\'on afecta esencialmente a modelos con datos de series temporales, aunque tambi\'en puede afectar a modelos con datos de secci\'on cruzada; en ese caso se conoce como autocorrelaci\'on espacial. Si las observaciones con datos transversales se ahn generado mediante muestreo aleatorio, los datos utilizados son por definici\'on independientes, y por tanto no puede haber autocorrelaci\'on espacial.

En el caso de series temporales es muy frecuente que el t\'ermino de error est\'e autocorrelacionado. Algunos de los motivos son:
\begin{itemize}
\item Existencia de ciclos o tendencias: Si la variable end\'ogena del modelo
presenta ciclos y \'estos no son bien explicados por las variables ex\'ogenas
del modelo, el t\'ermino de error presentar\'a autocorrelaci\'on, ya que
los errores grandes tender\'an a estar agrupados. Igualmente, si la
variable presenta una tendencia no bien explicada por las variables
explicativas, los t\'erminos de error ser\'an negativos al principio,
ir\'an disminuyendo y se har\'an positivos al final.
\item Variables omitidas: Si el verdadero modelo que explica el comportamiento
de la variable end\'ogena es:
\[
y_{i}=\beta_{1}+\beta_{2}x_{2i}+\beta_{3}x_{3i}+u_{i}
\]
pero se estima el modelo $y_{i}=\beta_{1}+\beta_{2}x_{2i}+v_{i}$,
entonces el t\'ermino de error es $v_{i}=u_{i}+\beta_{3}x_{3i}$. Si
la variable $x_{3}$ est\'a correlacionada consigo misma (tendencias,
ciclos, etc...), entonces $v_{t}$ presentar\'a correlaci\'on. En este
caso, la ausencia de variables en el modelo presenta otros problemas
aparte de la correlaci\'on, por lo que se deber\'ian intentar identificar
si se sospecha de su presencia.
\item Relaciones no lineales: Si la relaci\'on es no lineal, por ejemplo:
$y_{i}=\beta_{1}+\beta_{2}x_{i}+\beta_{3}x_{i}^{2}+u_{i}$. Si este
modelo se especifica de forma lineal, nos encontraremos con una racha
de residuos negativos, seguida de una racha de residuos positivos
para acabar con otra racha de residuos negativos, lo que generar\'a
autocorrelaci\'on del t\'ermino de error.
\item Relaciones din\'amicas: La mayor\'ia de relaciones entre variables econ\'omicas
se extienden a m\'as de un per\'iodo. As\'i, la relaci\'on entre la inflaci\'on
y el crecimiento de la oferta monetaria es del tipo $\pi_{t}=\beta_{1}+\beta_{2}m_{t}+\beta_{3}\pi_{t-1}+u_{t}$.
Si omitimos el retardo de la variable end\'ogena, el t\'ermino de error
del modelo incorporar\'a dicha variable, mostrando autocorrelaci\'on.
\end{itemize}

\subsectioncol{Consecuencias de la autocorrelaci\'on.}

Al igual que con le heteroscedasticidad, la autocorrelaci\'on no afecta a la insesgadez del estimador, siempre que las variables independientes sean ex\'ogenas.

En lo que se refiere a la consistencia, tampoco se ve afectada por la autocorrelaci\'on.

Sin embargo, el teorema de Gauss-Markov requiere de homoscedasticidad y no autocorrelaci\'on de los errores, por lo que el estimador MCO ya no ser\'a ELIO, y por tanto no ser\'a eficiente. Adem\'as, los errores est\'adary los estad\'isticos que hemos utilizado para realizar inferencia sobre los estimadores tampoco son ya v\'alidos, ni siquiera asint\'oticamente.

En cuanto a las medidas de bondad del ajuste, $R^2$ y $\bar{R}^2$, no se ven afectados siempre que los datos sean estacionarios y d\'ebilmente dependientes.

\sectioncol{Inferencia robusta a la heterocedasticidad y a la autocorrelaci\'on.}

\subsectioncol{Inferencia robusta a la heterocedasticidad.}

Puesto que los contrastes d ehip\'otesis acerca de los coeficientes del modelo son fundamentales en cualquier an\'alisis econom\'etrico, y dado que esta inferencia basada en el estimador MCO es incorrecta si aparece heteroscedasticidad, parece que tendremos que abandonar este estimador. Sin embargo, se han desarrollado una serie m\'etodos para ajustar los contrastes en presencia de heterocedasticidad de forma desconocida. Estos m\'etodos se conocen como m\'etodos \textit{robustos a la heterocedasticidad}, dado que al menos para muestras grandes son v\'alidos aun si no tenemos homoscedasticidad.

Tenemos el modelo lineal:

\begin{equation*}
\boldsymbol{y}=\boldsymbol{X\beta}+\boldsymbol{u}
\end{equation*}

Y se cumple que $Var(u_i|\boldsymbol{x}_i)=\sigma^2_i$, con los $\sigma^2_i$ no necesariamente iguales, y $Cov(u_i,u_j|\boldsymbol{x}_i)=0$ si $i\neq j$. Entonces, sabemos que:

\begin{align*}
\hat{\boldsymbol{\beta}}&=\boldsymbol{\beta}+\left(\boldsymbol{X}^{\prime}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{\prime}\boldsymbol{u} \\
Var(\hat{\boldsymbol{\beta}}|\boldsymbol{X})&=\left(\boldsymbol{X}^{\prime}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{\prime}Var(\boldsymbol{u}|\boldsymbol{X})\boldsymbol{X}\left(\boldsymbol{X}^{\prime}\boldsymbol{X}\right)^{-1} \\
\end{align*}

Y un estimador consistente de la varianza ser\'a:
\begin{equation*}
\hat{Var}(\hat{\boldsymbol{\beta}}|\boldsymbol{X})&=[n/(n-k)]\left(\boldsymbol{X}^{\prime}\boldsymbol{X}\right)^{-1}\left(\sum_{i=1}^n\hat{u}_i^2\boldsymbol{x}_i^{\prime}\boldsymbol{x}_i\right)\left(\boldsymbol{X}^{\prime}\boldsymbol{X}\right)^{-1} \\
\end{equation*}
