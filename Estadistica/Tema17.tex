\chapter[Fundamentos de la Inferencia Estad\'istica]{Fundamentos de la Inferencia Estad\'istica.\\
\normalsize Concepto de muestra aleatoria. Distribuci\'on de la muestra. Estad\'isticos y su distribuci\'on en el muestreo. Funci\'on de distribuci\'on emp\'irica y sus caracter\'isticas. Teorema de Glivenco-Cantelli.}

\sectioncol{Introducci\'on.}

Uno de los objetivos de la estad\'istica es obtener conclusiones acerca de una determinada poblaci\'on a partir de la observaci\'on de un subconjunto de miembros de la misma. A este proceso se le conoce con el nombre de \textbf{inferencia estad\'istica}, y se basa en todas las conclusiones y teoremas que nos ofrece el c\'alculo de probabilidad. La inferencia se puede realizar de dos formas: prediciendo el valor de un par\'ametro que defina a la poblaci\'on en cuesti\'on, en cuyo caso hablaremos de \textbf{estimaci\'on} del par\'ametro, o proponiendo una serie de hip\'otesis sobre la poblaci\'on y comprobando si se cumplen, caso en el que estaremos hablando de \textbf{contraste de hip\'otesis}.

\sectioncol{Concepto de muestra aleatoria.}

Para realizar cualquier inferencia acerca de una poblaci\'on necesitaremos obtener informaci\'on sobre la misma. En ausencia de otros condicionantes, la situaci\'on \'optima ser\'ia aquella en la que podemos estudiar a todos los miembros de la poblaci\'on, y as\'i nos aseguraremos que las conclusiones que obtengamos ser\'an completamente v\'alidas. Si embargo, en muchas ocasiones esto no es posible, ya sea por no poder acceder a todos los individuos, por el coste en el que incurrir\'iamos e incluso porque la observaci\'on de un individuo implique su destrucci\'on. En estos casos hemos de conformarnos con observar un subconjunto de miembros de la poblaci\'on, y a partir de esa observaci\'on inferir las caracter\'isticas poblacionales que nos interesen. A este subconjunto de la poblaci\'on que vamos a observar lo llamamos \textbf{muestra}. Por observar entendemos la medici\'on de uno o varios par\'ametros asociados a los individuos seleccionados, a los que llamaremos \textbf{par\'ametros muestrales}.

Aparece ahora el dilema de cual ser\'a la mejor forma de seleccionar esos individuos de forma que las conclusiones que obtengamos sean lo m\'as correctas posibles. Lo ideal ser\'ia que dicha muestra fuera una representaci\'on a escala de la poblaci\'on, es decir, sea representativa, pero dado que desconocemos las caracter\'isticas de la misma, en general esto no es posible.

Si ese subconjunto lo seleccionamos de manera aleatoria, podemos decir que las desviaciones entre la muestra que hemos seleccionado y una muestra totalmente representativa se deben al azar, y por tanto podemos asignarlas una probabilidad. As\'i, nos permitir\'a asignar conocer la probabilidad de que los resultados de nuestra inferencia sean exactos. Si procedemos de esta manera, diremos que hemos seleccionado una \textbf{muestra aleatoria}.

Dado que el valor de nuestras observaciones no lo conocemos a priori, la muestra se compondr\'a de tantas variables aleatorias como elementos contenga nuestra muestra (variables aleatorias muestrales) y una vez tomada la informaci\'on tendremos un conjunto de valores a los que llamaremos valores muestrales.

A esta forma de seleccionar la muestra se le llama muestreo probabil\'istico, y se puede realizar con reemplazamiento, en el que un mismo elemento puede estar presente m\'as de una vez en la muestra, y sin reemplazamiento, en el que cada elemento de la poblaci\'on estar\'a presente como mucho una vez en la muestra.

En la inferencia estudiaremos un tipo especial de muestras, las llamadas \textbf{muestras aleatorias simples}, que son muestras aleatorias con reemplazamiento en las que la probabilidad de un elemento de estar presente en la muestra es la misma para toda la poblaci\'on. En este tipo de muestras las variables aleatorias muestrales son independientes e id\'enticamente distribuidas, y su distribuci\'on de probabilidad es la misma que la del total de la poblaci\'on.

\begin{definicion}
Una \textbf{muestra aleatoria simple} de tama\~no $n$ est\'a formada por $n$ variables muestrales $X_1, X_2,\ldots, X_n$ independientes e id\'enticamente distribuidas, con la misma distribuci\'on de probabilidad que la caracter\'istica poblacional, $\xi$, a investigar.
\end{definicion}

\sectioncol{Distribuci\'on de la muestra.}

La distribuci\'on de probabilidad de la muestra nos dar\'a la probabilidad de obtenci\'on de cada muestra posible en una determinada poblaci\'on. En el caso de poblaciones cuya distribuci\'on de probabilidad sea discreta, la distribuci\'on de la muestra vendr\'a dada por todas las muestras posibles y sus respectivas probabilidades. En el caso continuo, consistir\'a en la funci\'on de densidad conjunta de las variables muestrales.

Sea una muestras, $(x_1\ldots,x_n)$. En el caso discreto tendremos:
\begin{equation*}
P(X_1=x_1,X_2=x_2,\ldots,X_n=x_n)=P(X_1=x_1)P(X_2=x_2/X_1=x_1)\cdots P(X_n=x_n/X_1=x_1,X_2=x_2,\ldots,X_{n-1}=x_{n-1})
\end{equation*}

Y, si hablamos de una muestra aleatoria simple, cada uno de los componentes de la muestra lo habremos extra\'ido de forma independiente, por tanto:

\begin{equation*}
P(X_1=x_1,X_2=x_2,\ldots,X_n=x_n)=P(X_1=x_1)P(X_2=x_2)\cdots P(X_n=x_n)
\end{equation*}

De forma an\'aloga, para el caso cont\'inuo y en el supuesto de muestra aleatoria simple, podemos obtener que:

\begin{equation*}
f(x_1,x_2,\ldots,x_n)=f(x_1)f(x_2)\cdots f(x_n)
\end{equation*}

\sectioncol{Estad\'isticos y su distribuci\'on en el muestreo.}

Definimos como estad\'istico cualquier funci\'on de los par\'ametros muestrales siempre que no contenga ning\'un par\'ametro desconocido. Lo denotaremos en general por $T(\mathbf{X})=T(x_1,\ldots,x_n)$.

Dado que los elementos de la muestra son variables aleatorias, los estad\'isticos tambi\'en ser\'an variables aleatorias, con un campo de variaci\'on y una distribuci\'on de probabilidad propios y determinados por el campo de variaci\'on y distribuci\'on de la poblaci\'on. Su campo de variaci\'on constar\'a de los valores que pueda tomar el estad\'istico para todos los elementos del espacio muestral, y su la probabilidad asociada a cada valor ser\'a igual a la suma de las probabilidades de todas las posibles muestras a partir de las cuales se obtenga ese valor.

A la distribuci\'on de probabilidad asociada a cada estad\'istico se la llama distribuci\'on de probabilidad del estad\'istico en el muestreo. SI conocemos esta distribuci\'on de probabilidad podremos realizar afirmaciones probabil\'isticas sobre nuestro estad\'istico.

Es muy importante tener en cuenta que los par\'ametros poblacionales son constantes, aunque en general desconozcamos su valor, mientras que los estad\'isticos muestrales son variables aleatorias.

A aquellos estad\'isticos cuyo valor nos sirve para estimar alg\'un par\'ametro de la poblaci\'on se les llama \textbf{estimadores}. Es por eso que la distribuci\'on del estad\'istico en el muestreo es tan importante, ya que nos puede dar informaci\'on acerca de cuan pr\'oximo es el estimador resultante al par\'ametro estimado.

\sectioncol{Funci\'on de distribuci\'on emp\'irica y sus caracter\'isticas.}

La funci\'on de distribuci\'on de probabilidad de una variable aleatoria se define como $F(x)=P(X\leq x)$. De manera an\'aloga, definimos la funci\'on de distribuci\'on emp\'irica de una muestra:
\begin{definicion}
Sea una poblaci\'on con una funci\'on de distribuci\'on $F(x)$. Sea una muestra aleatoria simple de la poblaci\'on, $(x_1,\ldots,x_n)$. Designamos por $N(x)$ el n\'umero de elementos de esa muestra cuyo valor en menor o igual que $x$. Entonces, definimos la funci\'on de distribuci\'on emp\'irica de la muestra aleatoria, que denotaremos por $F_n(x)$ como:
\begin{equation*}
F_n(x)=\dfrac{N(x)}{n}
\end{equation*}
\end{definicion}


La funci\'on de distribuci\'on emp\'irica no tiene relaci\'on directa con la funci\'on de distribuci\'on de la poblaci\'on ni la funci\'on de distribuci\'on en el muestreo, sin embargo existe una relaci\'on indirecta ya que se ha obtenido aleatoriamente a partir de la poblaci\'on y parece l\'ogico deducir que puede proporcionar una imagen aproximada de la distribuci\'on de probabilidad de la poblaci\'on de la que se extrajo la muestra.

Es por ello que es conveniente obtener sus momentos, llamados momentos muestrales. Dado que esta funci\'on de distribuci\'on le asigna una probabilidad de $\dfrac{1}{n}$ a cada elemento de la muestra, sus valores ser\'an:
\begin{itemize}
\item Momentos de orden $r$ respecto del origen:
\begin{equation*}
a_r=\dfrac{\sum_{i=1}^nx_i^r}{n}
\end{equation*}
\item Momentos de orden $r$ respecto de la media:
\begin{equation*}
m_r=\dfrac{\sum_{i=1}^n\left(x_i-\bar{x}\right)^r}{n}
\end{equation*}
\end{itemize}

Que como podemos comprobar son estad\'isticos, y por tanto variables aleatorias.

Entre estos momentos, los m\'as interesantes son la media muestral y la varianza muestral, $a_1$ y $m_2$. Vamos a estudiar su esperanza y su varianza.

\subsectioncol{Esperanza y varianza de la media muestral.}

\subsubsectioncol{Esperanza de la media muestral.}
\begin{equation*}
E\left(\bar{x}\right)=E\left(\dfrac{\sum_{i=1}^nx_i}{n}\right)=\dfrac{1}{n}\sum_{i=1}^nE\left(x_i\right)=\dfrac{1}{n}nE\left(\xi\right)=E\left(\xi\right)
\end{equation*}

Ya que al ser una muestra aleatoria simple, los elementos de la muestra se distribuyen igual que la poblaci\'on y tendr\'an su misma esperanza. Por tanto, este resultado es v\'alido para cualquier muestra aleatoria simple independientemente de la poblaci\'on de la que proceda.

\subsubsectioncol{Varianza de la media muestral.}

\begin{equation*}
V\left(\bar{x}\right)=V\left(\dfrac{\sum_{i=1}^nx_i}{n}\right)=\dfrac{1}{n^2}V\left(\sum_{i=1}^nx_i\right)=\dfrac{1}{n}nE\left(\xi\right)=E\left(\xi\right)=\mu
\end{equation*}

Y como las variables son independientes entre s\'i, por ser MAS:
\begin{equation*}
\dfrac{1}{n^2}V\left(\sum_{i=1}^nx_i\right)=\dfrac{1}{n^2}\sum_{i=1}^nV\left(x_i\right)=\dfrac{V(\xi)}{n}=\dfrac{\sigma^2}{n}
\end{equation*}

Como podemos ver, siempre que la varianza de la poblaci\'on sea finita, la media de la muestra estar\'a m\'as concentrada en torno a la media poblacional cuanto mayor sea el tama\~no de la muestra. En consecuencia, cuanto mayor sea el tama\~no de la muestra m\'as confianza tenemos en que la media muestral sea una buena estimaci\'on de la media poblacional.

Otro hecho de relevancia es que, como consecuencia del Teorema Central del L\'imite, independientemente del modelo de distribuci\'on
de la variable poblacional, para tama\~nos muestrales elevados la media muestral aleatoria tiende a distribuirse como una normal con la esperanza y varianza anteriormente expuestas.

\subsectioncol{Esperanza y varianza de la varianza muestral.}

\subsubsectioncol{Esperanza de la varianza muestral.}

\begin{equation*}
m_2=S_x^2=\dfrac{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}{n}=\dfrac{\sum_{i=1}^n\left(x_i-\mu+\mu-\bar{x}\right)^2}{n}=
\end{equation*}

\begin{equation*}
=\dfrac{\sum_{i=1}^n\left(x_i-\mu\right)^2-2\left(x_i-\mu\right)\left(\bar{x}-\mu\right)+\left(\bar{x}-\mu\right)^2}{n}=\dfrac{\sum_{i=1}^n\left(x_i-\mu\right)^2}{n}-\left(\bar{x}-\mu\right)^2
\end{equation*}

\begin{equation*}
E\left(S_x^2\right)=E\left(\dfrac{\sum_{i=1}^n\left(x_i-\mu\right)^2}{n}\right)-E\left(\left(\bar{x}-\mu\right)^2\right)=V(\xi)-\dfrac{v(\xi}{n}=\dfrac{n-1}{n}\sigma^2
\end{equation*}

\subsubsectioncol{Varianza de la varianza muestral.}

Esta demostraci\'on es bastante engorrosa. El sesultado fina es:
\begin{equation*}
V\left(S_x^2\right)=\dfrac{\mu_4-\sigma^4}{n}-2\dfrac{\mu_4-2\sigma^4}{n^2}+\dfrac{\mu_4-3\sigma^4}{n^3}
\end{equation*}

\sectioncol{Teorema de Glivenco-Cantelli.}

\begin{teorema}
Sea $(X_1,\ldots,X_n)$ una muestra aleatoria simple obtenida de una poblaci\'on con funci\'on de distribuci\'on $F(x)$. Sea $F_n^*(x)=\dfrac{1}{n}\sum_{i=1}^nI_{(-\infty,x](X_i)}$ su funci\'on de distribuci\'on emp\'irica. entonces se cumple que 
\begin{equation*}
sup_{x\in\mathbb{R}}\left|F_n^*(x)-F(x)\right|\overset{c.s.}{\to}0
\end{equation*}

\end{teorema}

El Teorema nos dice que si definimos una banda de amplitud $\varepsilon$ arbitrariamente estrecha entorno a la distribuci\'on de probabilidad te\'orica de la poblaci\'on en estudio, para un tama\~no de muestra suficientemente grande podemos asegurar con probabilidad 1 que la funci\'on de distribuci\'on emp\'irica estar\'a contenida en esa banda.